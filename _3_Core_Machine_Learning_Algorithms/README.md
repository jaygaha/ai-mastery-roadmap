# Core Machine Learning Algorithms
 
 Now that our data is clean and prepped, it's time to build the brains of our operation: the models. In this module, we'll explore the fundamental algorithms that power machine learning.
 
 ## Modules
 
 ### 1. Supervised Learning Paradigms: Regression vs Classification
 Located in: `_01_Supervised_Learning_Paradigms_Regression_vs_Classification`
 
 Understand the two main pillars of supervised learning:
 - **Regression**: Predicting continuous values (like prices or temperatures).
 - **Classification**: Predicting categories (like spam vs. ham or churn vs. stay).

### 2. Linear Regression: Theory, Assumptions, and Practical Implementation
Located in: `_02_Linear_Regression`

Master the simple yet powerful linear model:
- Understand the math behind the "best fit line".
- Learn the 5 critical checks (assumptions) to ensure your model is valid.
- Implement it from scratch using Scikit-Learn.

### 3. Logistic Regression: Theory, Probabilistic Classification, and Practical Implementation
Located in: `_03_Logistic_Regression`

The fundamental classification algorithm:
- Understand how S-curves map numbers to probabilities.
- Learn about Decision Boundaries and Thresholds.
- Implement a churn prediction model.

### 4. Decision Trees and Ensemble Methods (Random Forests): Theory and Implementation
Located in: `_04_Decision_Trees_and_Ensemble_Methods`

Intuitive and powerful non-linear models:
- **Decision Trees:** Like a game of "20 Questions" to classify data.
- **Random Forests:** Tapping into the "Wisdom of the Crowd" (Ensemble) for better accuracy.
- Practice hyperparameter tuning.

### 5. Model Evaluation Metrics for Regression
Located in: `_05_Model_Evaluation_Metrics_for_Regression`

Learn how to evaluate your regression models:
- **MAE**: The average miss.
- **MSE/RMSE**: Penalizing large errors.
- **R-Squared**: Goodness of fit.